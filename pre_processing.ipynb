{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:12:46.525913Z",
     "start_time": "2024-10-21T09:12:46.516119Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from issue import Issue\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:10.196905Z",
     "start_time": "2024-10-21T09:12:47.723733Z"
    }
   },
   "source": [
    "DATA_FILE_PATH = \"vscode_no_prs.csv.gzip\" # \"../teste.csv.gzip\" # \"../vscode_issues_SA.csv.gzip\"\n",
    "\n",
    "sample_dataset = pd.read_csv(DATA_FILE_PATH, compression='gzip', lineterminator='\\n')\n",
    "\n",
    "issues_dict_list = sample_dataset.to_dict('records')\n",
    "\n",
    "issues = []\n",
    "test_dataset = []\n",
    "\n",
    "# Initialize commit_no_by_author dictionary\n",
    "commit_no_by_author = {}\n",
    "\n",
    "for issue_dict in tqdm(issues_dict_list):\n",
    "    try:\n",
    "        new_issue = Issue.from_dict(issue_dict)\n",
    "        issues.append(new_issue)\n",
    "\n",
    "        # Move author-related logic inside the try block with correct indentation\n",
    "        author = new_issue.assignee\n",
    "        if author:  # Ensure author is not None\n",
    "            if commit_no_by_author.get(author) is None:\n",
    "                commit_no_by_author[author] = 1\n",
    "            else:\n",
    "                commit_no_by_author[author] += 1\n",
    "    except Exception as e:\n",
    "        pass"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184819/184819 [00:18<00:00, 9744.06it/s] \n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:11.788141Z",
     "start_time": "2024-10-21T09:13:11.785208Z"
    }
   },
   "source": [
    "print(len(issues))\n",
    "print(len(commit_no_by_author))\n",
    "print(commit_no_by_author)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184812\n",
      "116\n",
      "{'mjbvz': 15630, 'rzhao271': 1423, 'lszomoru': 3903, 'roblourens': 9410, 'alexr00': 3423, 'sandy081': 8016, 'aiday-mar': 832, 'meganrogge': 5018, 'deepak1556': 4121, 'Tyriar': 12408, 'jrieken': 9073, 'bpasero': 11117, 'joshspicer': 42, 'justschen': 389, 'benibenj': 601, 'andreamah': 1163, 'alexdima': 7050, 'ulugbekna': 431, 'hediet': 2520, 'chrmarti': 1819, 'joaomoreno': 9579, 'connor4312': 2725, 'lramos15': 1832, 'TylerLeonhardt': 2089, 'karthiknadig': 25, 'rebornix': 5550, 'bhavyaus': 406, 'aeschli': 7067, 'Yoyokrazy': 302, 'eleanorjboyd': 32, 'amunger': 323, 'anthonykim1': 10, 'sbatten': 2510, 'joyceerhl': 479, 'isidorn': 7503, 'daviddossett': 338, 'DonJayamanne': 280, 'dbaeumer': 1879, 'bamurtaugh': 10, 'ntrogh': 3, 'chrisdias': 293, 'kieferrm': 314, 'hbons': 86, 'karrtikr': 15, 'cwebster-99': 1, 'digitarald': 79, 'brettcannon': 10, 'MeghanKulkarni': 17, 'paulacamargo25': 7, 'gregvanl': 102, 'danyeh': 122, 'esonnino': 7, 'csigs': 5, 'Chuxel': 6, 'weinand': 2712, 'egamma': 774, 'DanielRosenwasser': 1, 'stevencl': 126, 'IanMatthewHuff': 5, 'tanhakabir': 68, 'miguelsolorio': 554, 'devinvalenciano': 4, 'sadasant': 1, 'minsa110': 4, 'rchiodo': 8, 'greazer': 2, 'JacksonKearl': 1175, 'lychung7': 1, 'orta': 1, 'sana-ajani': 16, 'sanket856': 1, 'eamodio': 567, 'dynamicwebpaige': 1, 'manav014': 1, 'stuartleeks': 1, 'xisui-MSFT': 1, 'kimadeline': 1, 'ItalyPaleAle': 1, 'RMacfarlane': 770, 'claudiaregio': 1, 'nexue2020': 7, 'fiveisprime': 24, 'ornelladotcom': 1, 'btholt': 2, '9at8': 6, 'octref': 684, 'janbaltus': 11, 'bowdenk7': 3, 'cleidigh': 45, 'djdakta': 1, 'weeteckt': 1, 'lukaschal': 47, 'auchenberg': 34, 'awvalenti': 1, 'foucdeg': 1, 'Steam-Rabbit': 1, 'ramya-rao-a': 786, 'shawndon': 2, 'albu77': 1, 'gushuro': 10, 'tsalinger': 12, 'seanmcbreen': 69, 'johnliu369': 17, 'daviwil': 15, 'Lixire': 12, 'michelkaporin': 76, 'waderyan': 390, 'aefernandes': 1, 'mousetraps': 20, 'bgashler1': 69, 'vsccarl': 23, 'v-pavanp': 15, 'delmyers': 4, 'sofianhn': 21, 'pjmeyer': 1, 'lukehoban': 1}\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:16.635465Z",
     "start_time": "2024-10-21T09:13:16.632257Z"
    }
   },
   "source": [
    "def apply_steps_to_dataset(processing_funcs, dataset):\n",
    "\t\"\"\"\n",
    "\tGiven a list of preocessing functions and a dataset (list of issues), \n",
    "\tapplies each function to the dataset in the order given.\n",
    "\n",
    "\tEach function must return the altered issue, unless they are\n",
    "\tsupposed to be filtered out, in which case the function \n",
    "\tmust return None.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tnew_issues = []\n",
    "\n",
    "\tfor issue in dataset:\n",
    "\t\tfor func in processing_funcs:\n",
    "\t\t\tissue = func(issue)\n",
    "\t\t\tif issue is None:\n",
    "\t\t\t\tbreak\n",
    "\t\tif issue is not None:\n",
    "\t\t\tnew_issues.append(issue)\n",
    "\t\n",
    "\tprint(\"New dataset has \" + str(len(new_issues)) + \" issues\")\n",
    "\n",
    "\treturn new_issues"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:19.659066Z",
     "start_time": "2024-10-21T09:13:19.656039Z"
    }
   },
   "source": [
    "def filter_test_dataset(issue):\n",
    "\t\"\"\"\n",
    "\tChecks the issue id. If it is in the range of the test set (210000 < id <= 220000),\n",
    "\treturn the issue. Otherwise, return None.\n",
    "\t\"\"\"\n",
    "\tissue_id = int(issue.identifier)\n",
    "\tif 210000 < issue_id <= 220000:\n",
    "\t\treturn issue\n",
    "\treturn None"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:21.726449Z",
     "start_time": "2024-10-21T09:13:21.723890Z"
    }
   },
   "source": [
    "def filter_main_training_dataset(issue):\n",
    "\t\"\"\"\n",
    "\tChecks the issue id. If it is in the range of the larger training set (id <= 210000),\n",
    "\treturn the issue. Otherwise, return None.\n",
    "\t\"\"\"\n",
    "\tissue_id = int(issue.identifier)\n",
    "\tif issue_id <= 210000:\n",
    "\t\treturn issue\n",
    "\treturn None"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:23.149776Z",
     "start_time": "2024-10-21T09:13:23.146867Z"
    }
   },
   "source": [
    "def filter_recent_issues_training_dataset(issue):\n",
    "\t\"\"\"\n",
    "\tChecks the issue id. If it is in the range of the training set which only contains\n",
    "\trecent issues (190000<= id <= 210000), return the issue. Otherwise, return None.\n",
    "\t\"\"\"\n",
    "\tissue_id = int(issue.identifier)\n",
    "\tif 190000 <= issue_id <= 210000:\n",
    "\t\treturn issue\n",
    "\treturn None"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:24.891563Z",
     "start_time": "2024-10-21T09:13:24.888501Z"
    }
   },
   "source": [
    "def filter_basic_trainingset_requirements(issue):\n",
    "\t\"\"\"\n",
    "\tChecks if a given issue corresponds to the basic requirements for the\n",
    "\ttraining set are met. These are vscode's issues that \n",
    "\t\t(i) are closed; \n",
    "\t\t(ii) have exactly one assignee;\n",
    "\t\"\"\"\n",
    "\t# Check if the issue is closed\n",
    "\tif issue.completion_time is None:\n",
    "\t\treturn None\n",
    "\t\n",
    "\t# Check if the issue has exactly one assignee\n",
    "\tif issue.assignee is None or (isinstance(issue.assignee, list) and len(issue.assignee) != 1):\n",
    "\t\treturn None\n",
    "\t\n",
    "\t# If both conditions are met, return the issue\n",
    "\treturn issue"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:26.767577Z",
     "start_time": "2024-10-21T09:13:26.764581Z"
    }
   },
   "source": [
    "def filter_unfrequent_commiters(issue):\n",
    "    \"\"\"\n",
    "    Filters out issues from authors with commit counts less than or equal to the threshold.\n",
    "    \"\"\"\n",
    "    threshold = 1  # Set the threshold for filtering commit counts\n",
    "    \n",
    "    author = issue.assignee\n",
    "    \n",
    "    # Check if the author exists and their commit count is above the threshold\n",
    "    if author is None or commit_no_by_author.get(author, 0) <= threshold:\n",
    "        return None\n",
    "    \n",
    "    return issue"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:28.600355Z",
     "start_time": "2024-10-21T09:13:28.597194Z"
    }
   },
   "source": [
    "def clean_issue_title(issue):\n",
    "\t\"\"\"\n",
    "\tCleans the issue field of the given issue.\n",
    "\t\"\"\"\n",
    "\tnew_title = issue.summary\n",
    "\n",
    "\t# Remove mention to other issues\n",
    "\tnew_title = re.sub(r\"\\[?\\s*[Ff]ollow up to #?[\\d]+\\s*\\]?\", \"\", new_title)\n",
    "\n",
    "\t# Remove monospacing markdown formatting\n",
    "\tnew_title = re.sub(r\"`([\\s\\S]*?)`\", r\"\\1\", new_title)\n",
    "\n",
    "\t# Update the issue summary\n",
    "\tissue.summary = new_title\n",
    "\t\n",
    "\t# Return the updated issue object\n",
    "\treturn issue\n"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:30.182295Z",
     "start_time": "2024-10-21T09:13:30.177163Z"
    }
   },
   "source": [
    "## BE CAREFUL IF ALTERING THESE CONSTANTS.\n",
    "# They should be the same used for training the model in the training notbook (.ipynb)\n",
    "CODE_BEGIN_SENTINEL = \"<BoC>\"\n",
    "CODE_END_SENTINEL = \"<EoC>\"\n",
    "\n",
    "def clean_issue_body(issue):\n",
    "\t\"\"\"\n",
    "\tCleans the body field of the given issue.\n",
    "\tAdditionally, envolves code fragments using the sentinel tokens\n",
    "\tfrom the training notebook.\n",
    "\t\"\"\"\n",
    "\n",
    "\tissue_body = issue.body\n",
    "\n",
    "\tif issue_body is None:\n",
    "\t\treturn \"\"\n",
    "\n",
    "\tcode_fragments = \"\"\n",
    "\n",
    "\tnew_body = issue_body\n",
    "\n",
    "\t#  TODO: Dont just isolate all fragments, but preserve\n",
    "\t# their place in the issue body, surrounding them with \n",
    "\t# the sentinel tokens\n",
    "\n",
    "\t## Note code fragments\n",
    "\tfor match in re.findall(r\"```([\\s\\S]*?)```\", new_body):\n",
    "\t\tcode_fragments += CODE_BEGIN_SENTINEL + match + CODE_END_SENTINEL + \"\\n\"\n",
    "\n",
    "\tnew_body = re.sub(r\"```([\\s\\S]*?)```\", \"\", new_body)\n",
    "\n",
    "\t# Remove headers\n",
    "\tnew_body = re.sub(\"#+ \", \"\", new_body)\n",
    "\n",
    "\t# Removing emphasis might interfere with code fragments\n",
    "\t# Watchout if you want to fill the TODO, as these lines\n",
    "\t# will have to be taken care of\n",
    "\n",
    "\tnew_body = re.sub(r\"_([\\s\\S]*?)_\", r\"\\1\", new_body)\n",
    "\tnew_body = re.sub(r\"\\*([\\s\\S]*?)\\*\", r\"\\1\", new_body)\n",
    "\tnew_body = re.sub(r\"`(\\s[\\S]*?)`\", r\"\\1\", new_body)\n",
    "\n",
    "\t# Remove html tags\n",
    "\tnew_body = re.sub(r\"<[\\s\\S]*?>\", r\"\", new_body)\n",
    "\n",
    "\t# Remove markdown links\n",
    "\tnew_body = re.sub(r\"\\!?\\[[\\s\\S]+\\]\\([\\S]+\\)\", \"\", new_body)\n",
    "\n",
    "\t# Remove attachments\n",
    "\tnew_body = re.sub(r\"https?://[\\S]+\", \"\", new_body)\n",
    "\n",
    "\tnew_body = re.sub(r\"[\\s]*\\n+\", \"\\n\", new_body)\n",
    "\n",
    "\tnew_body = code_fragments + new_body\n",
    "    \n",
    "\tissue.body = new_body\n",
    "\n",
    "\t# Return the modified issue object\n",
    "\treturn issue\n"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing the Issue Datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:46.726235Z",
     "start_time": "2024-10-21T09:13:33.673204Z"
    }
   },
   "source": [
    "clean_dataset = apply_steps_to_dataset([filter_basic_trainingset_requirements,\\\n",
    "\t\t\t\t\t\t\t\t\t\tfilter_unfrequent_commiters,\\\n",
    "\t\t\t\t\t\t\t\t\t\tclean_issue_title,\\\n",
    "\t\t\t\t\t\t\t\t\t\tclean_issue_body],issues)\n",
    "\n",
    "main_training_dataset = apply_steps_to_dataset([filter_main_training_dataset],clean_dataset)\n",
    "recent_issues_training_dataset = apply_steps_to_dataset([filter_recent_issues_training_dataset],clean_dataset)\n",
    "test_dataset = apply_steps_to_dataset([filter_test_dataset],clean_dataset)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset has 142391 issues\n",
      "New dataset has 135926 issues\n",
      "New dataset has 10299 issues\n",
      "New dataset has 3135 issues\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results to a new file"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:13:51.038208Z",
     "start_time": "2024-10-21T09:13:51.035238Z"
    }
   },
   "source": [
    "def save_issue_repo(new_path,issue_repo):\n",
    "\tissues_as_dicts = []\n",
    "\tprint(\"Parsing collected issues.\\nThis might take a few minutes\")\n",
    "\n",
    "\tfor issue in tqdm(issue_repo):\n",
    "\t\t# print(vars(issue))\n",
    "\t\n",
    "\t\tissues_as_dicts.append(issue.to_dict())\n",
    "\n",
    "\tissues_as_dataset = pd.DataFrame.from_dict(issues_as_dicts)\n",
    "\tissues_as_dataset.to_csv(new_path, compression='gzip', index=False)"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T09:19:00.486035Z",
     "start_time": "2024-10-21T09:18:53.823907Z"
    }
   },
   "source": [
    "MAIN_TRAINING_DESTINATION_PATH = \"train_A.csv.gzip\"\n",
    "RECENT_TRAINING_DESTINATION_PATH = \"train_B.csv.gzip\"\n",
    "TEST_DESTINATION_PATH = \"test.csv.gzip\"\n",
    "\n",
    "save_issue_repo(MAIN_TRAINING_DESTINATION_PATH,main_training_dataset)\n",
    "save_issue_repo(RECENT_TRAINING_DESTINATION_PATH,recent_issues_training_dataset)\n",
    "save_issue_repo(TEST_DESTINATION_PATH,test_dataset)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing collected issues.\n",
      "This might take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135926/135926 [00:00<00:00, 3421771.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing collected issues.\n",
      "This might take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10299/10299 [00:00<00:00, 4049605.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing collected issues.\n",
      "This might take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3135/3135 [00:00<00:00, 3279088.04it/s]\n"
     ]
    }
   ],
   "execution_count": 67
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
